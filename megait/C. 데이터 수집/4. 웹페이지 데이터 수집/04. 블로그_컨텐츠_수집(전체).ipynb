{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 블로그 컨텐츠 수집(전체)\n",
    "\n",
    "데이터가 대량으로 수집되어야 하는 경우 일부에 대한 처리 코드를 완성하고 이를 모듈화(함수)하여 재사용하면 대량의 데이터 수집이 가능하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #01. 준비과정\n",
    "### [1] 패키지 참조\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #02. 데이터 요청하기\n",
    "### [1] 세션요청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "\n",
    "session.headers.update({\n",
    "    \"Referer\": \"\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] 웹 페이지 소스코드 가져오기\n",
    "\n",
    "1. 앞서 구현한 코드를 모두 하나의 블록으로 모은다.\n",
    "2. 모아놓은 코드를 함수로 묶는다. \n",
    "   - 접근URL을 파라미터로 처리한다.\n",
    "3. 함수 안에서 생성된 결과값은 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContents(session, url):\n",
    "    try:\n",
    "        r = session.get(url)\n",
    "        \n",
    "        if r.status_code != 200:\n",
    "            msg = \"[%d Error] %s 에러가 발생함\" % (r.status_code, r.reason)\n",
    "            raise Exception(msg)\n",
    "    except Exception as e:\n",
    "        print(\"접속에 실패했습니다.\")\n",
    "        print(e)\n",
    "\n",
    "\n",
    "    r.encoding = \"utf-8\"\n",
    "    soup = BeautifulSoup(r.text)\n",
    "\n",
    "    post = soup.select('.post')\n",
    "    mydata =[]\n",
    "    for i, v in enumerate(post):\n",
    "        # print(v)\n",
    "\n",
    "        # 하나의 글 안에서 제목 영역을 찾는다.\n",
    "        entryTitle = v.select(\".entry-title a\")\n",
    "        # print(entryTitle)\n",
    "\n",
    "        # 추출된 요소가 각 게시글 안에서 하나만 존재하므로 `0`번째 원소에 직접 접근한다.\n",
    "        title = entryTitle[0].text.strip()\n",
    "        # print(title)\n",
    "\n",
    "        # 클릭시 이동할 페이지의 주소\n",
    "        if 'href' in entryTitle[0].attrs:\n",
    "            href = entryTitle[0].attrs['href']\n",
    "\n",
    "        # 같은 페이지 내에서 주소 이동할 경우 도메인 생략가능\n",
    "            \n",
    "        # 수집된 주소에 도메인이 없다면 덧붙여준다\n",
    "        if url not in href:\n",
    "            href = url+href\n",
    "\n",
    "        else:\n",
    "            href = None\n",
    "        # print(href)\n",
    "\n",
    "        # 작성일\n",
    "        published = v.select(\".published\")\n",
    "        # print(published)\n",
    "        datetime = published[0].attrs['datetime']\n",
    "        # print(datetime)\n",
    "        \n",
    "        # 요약글\n",
    "        entryContent = v.select(\".entry-content p\")\n",
    "        # print(entryContent)\n",
    "\n",
    "        # 마지막의 `more` 버튼은 제거한다.\n",
    "        # entryContent = entryContent[:-1] # python적 접근\n",
    "        # print(entryContent)\n",
    "\n",
    "        entryContent = v.select(\".entry-content p:not(.read-more)\") # CSS적 접근\n",
    "        # print(entryContent)\n",
    "\n",
    "        text = ''\n",
    "        for j, e in enumerate(entryContent): # 2개 이상인 경우도 있으므로 반복문\n",
    "            text += \" \" +e.text.strip() if j>0 else e.text.strip()\n",
    "        # print(text)\n",
    "\n",
    "        # 태그\n",
    "        tagLinks = v.select(\".tag-links a\")\n",
    "        # print(tagLinks)\n",
    "\n",
    "        \n",
    "        for j,e in enumerate(tagLinks):\n",
    "            tagLinks[j] = e.text.strip()\n",
    "        \n",
    "        tags = ','.join(tagLinks)\n",
    "        \n",
    "        # 수집된 정보를 하나의 딕셔너리로 묶는다 => 처리방법은 다르게해도 상관 없음\n",
    "        mydict = {\n",
    "            \"title\":title,\n",
    "            \"href\":href,\n",
    "            \"datetime\":datetime,\n",
    "            \"text\":text,\n",
    "            \"tags\":tags\n",
    "        }\n",
    "        mydata.append(mydict)\n",
    "    return mydata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] 구현된 기능 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = getContents(session, 'https://blog.hossam.kr')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] 반복문에서 주소 패턴을 구성하여 수행\n",
    "#### 접근 URL의 패턴 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://blog.hossam.kr\"\n",
    "urlFmt = \"%s/blog/page{pagenumber}\" %url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최대 페이지 수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxPage = 22\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수집된 전체 게시글 수 : 108\n"
     ]
    }
   ],
   "source": [
    "blogPosts = []\n",
    "for i in range(1,maxPage+1):\n",
    "    targetUrl = urlFmt.format(pagenumber = i) if i>1 else url\n",
    "    blogPosts += getContents(session,targetUrl)\n",
    "\n",
    "print(\"수집된 전체 게시글 수 :\",len(blogPosts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [5] 수집 결과 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = dt.datetime.now().strftime(\"블로그_글_수집_%y%m%d_%H%M%S.csv\")\n",
    "\n",
    "with open(fname, 'w', encoding='utf-8') as f:\n",
    "    for i,v in enumerate(blogPosts):\n",
    "        if i ==0 : \n",
    "            title = f'{\",\".join(v.keys())}\\n'\n",
    "            # print(title)\n",
    "            f.write(title)\n",
    "        \n",
    "        content = list(v.values())\n",
    "\n",
    "        # print(content)\n",
    "        # csv에 저장하기 위해서\n",
    "        # 1) 각 컨텐츠 안에 포함된 쌍따옴표는 역슬래시로 묶어준다\n",
    "        # 2) 각 컨텐츠를 쌍따옴표로 묶어준다.\n",
    "        for j,w in enumerate(content):\n",
    "            content[j] = f'\"{w.replace('\"',r'\\\"')}\"'\n",
    "        # print(content)\n",
    "        f.write(f'{\",\".join(content)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
